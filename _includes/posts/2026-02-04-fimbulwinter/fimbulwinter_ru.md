## Резюме

Статья исходит из формальной логики и определений (сетевой эффект, закон возрастания энтропии, антизависимость, философия «нуля» нулевой предельной выгоды), систематически обозревает крупные сбои основных публичных облаков и инфраструктуры — Alibaba Cloud, Google Cloud, Azure, Cloudflare, Tencent Cloud — с 2014 по 2025 год и сравнивает прозрачность их отчётности по сбоям. На этой основе анализируются «причины смерти» публичного облака: энтропия ПО и нулевая предельная выгода затрудняют управление устаревшим кодом и архитектурой; сетевые эффекты усиливают каскадные сбои; компенсации по SLA серьёзно не соответствуют реальным потерям предприятий и госсектора. Автор рекомендует крупным предприятиям и госорганам приоритизировать «антизависимость» от одного публичного облака и предлагает концепцию «высокодоступной системы с малой параллельной нагрузкой» — снижение риска единой точки отказа и радиуса поражения за счёт избыточности хранения и распределения трафика (например, мультирегиональное, мультикластерное DNS-разрешение).

![Фимбульвинтер](/img/in-post/fimbulwinter/fimbulwinter.jpeg)

## Формальная логика и определения

**Сетевой эффект**: чем больше пользователей (или участников) у продукта/сервиса/платформы, тем выше его ценность для каждого пользователя.

**Закон возрастания энтропии**: кодовую базу проекта со временем ожидает превращение в «свалку».

**Антизависимость**: обратная зависимость от одного языка программирования, стека или облачной платформы. Примеры: полиглот-программирование, мультистек, мультиоблако. Антизависимость позволяет бизнесу стабильно работать без привязки к одному языку, открытому проекту или публичному облаку.

**Ноль**: рефакторинг с нулевой предельной выгодой никому не нужен.


## Сбои Alibaba Cloud

С 2014 по 2025 год у Alibaba Cloud не было аномально большого числа **крупных инцидентов**, широко освещённых и официально раскрытых, **действительно широких по охвату, длительных и называемых «крупными авариями»** (по масштабу компании общий SLA по-прежнему на уровне лидеров отрасли). Однако несколько из них действительно вызвали заметные общественные последствия и отраслевую дискуссию. Ниже — хронологический список **крупных сбоев** (по открытым отчётам, официальным заявлениям, СМИ и разборам сообщества):

| Время | Регион/охват | Длительность | Основное влияние и последствия | Официальная/основная причина | Заметки/оценка отрасли |
|-------|--------------|--------------|--------------------------------|------------------------------|------------------------|
| Июнь 2018 | Часть регионов (детали не раскрыты) | ~30 мин | Сбои части облачных продуктов, ограниченное влияние | Подробно не раскрыто | Часть СМИ назвала «крупным техническим сбоем» |
| 3 марта 2019 | Северный Китай 2 (Пекин) AZ-C | Часы | Массовые сбои дисков ECS, падение множества сайтов/приложений | Сбой дисков | Существенное влияние; Alibaba Cloud компенсировала по SLA |
| 18 декабря 2022 | Регион Гонконг AZ-C | ~15,5 ч | Почти полная остановка Гонконга; недоступность ключевых сайтов Макао (денежно-кредитное управление, Galaxy, Lotus TV и др.); затронут OKX | Отказ охлаждения → каскад → массовый простой | Широко названо «одним из худших инцидентов в истории Alibaba Cloud» |
| 12 ноября 2023 | **Все регионы и сервисы глобально** | ~3 ч 16 мин | Консоль, API, MQ, микросервисы, мониторинг, ML и др. в сбое; Taobao, DingTalk, Xianyu, Ele.me, Alibaba Cloud Drive и др. упали | Сбой ядра (аутентификация/метаданные/контрольная плоскость) | **Широко признано худшим и самым широким сбоем Alibaba Cloud**; «эпический», «беспрецедентный в отрасли» |
| 27 ноября 2023 | Часть серверов | ~2 ч | Сбой доступа к серверам | Подробно не раскрыто | Всего через полмесяца после 11·12; новые вопросы к доверию |
| 2 июля 2024 | Часть регионов/сервисов | Часы | Сбои консоли и части сервисов | Детального разбора нет | Средний масштаб; влияние меньше предыдущих |
| 2025 (дата неясна) | Глобально (подозрение на DNS) | ~6 ч | Подмена DNS привела к глобальным сбоям сервисов | Подмена DNS | По сводке сбоев публичного облака 2025; детали уточняются |

### Важные замечания и тренды

1. **2014–2018, ранний период**: Публично раскрытых крупных P0-инцидентов в этот период крайне мало; в основном локальные, ограниченные случаи. Масштаб был намного меньше, влияние — тоже.

2. **Два самых тяжёлых**:
   - **2022.12 Гонконг 15,5 ч** → Самый длительный сбой в одном регионе; тяжёлое влияние на критическую инфраструктуру Гонконга и Макао.
   - **2023.11.12 глобально 3+ ч** → Остановка контрольной плоскости и глобальных сервисов; широко признано редким сбоем «все регионы × все сервисы», развенчавшим миф о «мультиактивности, мультицентре, N девяток».

3. **2024–2025**: По известным данным частота и тяжесть ниже, чем в 2022–2023, но средние и крупные события по-прежнему случаются (например, подмена DNS в 2025 году имела широкий охват).

4. **Подход Alibaba Cloud**: После большинства крупных сбоев публикуются детальные разборы (особенно по Гонконгу 2022 и глобальному 2023); компенсация по SLA (обычно ваучеры); официальные извинения руководства.

В целом за 2014–2025 у Alibaba Cloud порядка **5–7** инцидентов уровня «крупная авария», при этом **12 ноября 2023** и **декабрь 2022 Гонконг** общепризнанно считаются двумя самыми тяжёлыми.


## Сбои Google Cloud

Google Cloud Platform (GCP) с 2014 по 2025 год имел в целом хороший SLA; **крупные инциденты**, реально затронувшие **глобальный охват** или **несколько ключевых сервисов**, не были особенно частыми (меньше глобальных катастроф, чем у AWS и Azure). Когда они происходили, часто страдали многие сторонние приложения (Snapchat, Spotify, Discord, сервисы, зависящие от Cloudflare и т.д.) с высоким общественным резонансом.

Ниже — хронологический список **серьёзных, широких по охвату** сбоев GCP (по открытому Status Dashboard, СМИ, Wikipedia, отраслевым разборам):

| Время | Регион/охват | Длительность | Основное влияние и последствия | Основная причина | Заметки/оценка отрасли |
|-------|--------------|--------------|--------------------------------|------------------|------------------------|
| Август 2015 | Европа (Глин, Бельгия) | Часы | Очень высокая доля ошибок чтения/записи Compute Engine; частичная потеря данных | Молния повредила часть ЦОД | Google редко признаёт **потерю данных**; ограниченный круг заказчиков |
| Июль 2018 | Глобально (несколько регионов) | Часы | Сбои сервисов GCP; Snapchat, Spotify и др. в основном недоступны | Перегрузка сети + внутренняя маршрутизация | Широко освещено; сильное влияние на третьи стороны |
| 2 июня 2019 | Восток США + глобально | ~4–5 ч | Массовые сбои YouTube, Gmail, G Suite; сбои входа Snapchat, Discord, Vimeo | Перегрузка сети на востоке США + каскад | Широкий охват; активное обсуждение в соцсетях |
| 14 декабря 2020 | Глобально | ~1 ч | Gmail, YouTube, Google Home, Nest, Pokémon GO и др. — почти все сервисы, зависящие от аутентификации, упали | Глобальный сбой системы идентификации (аналог IAM) | «Падение» потребительских сервисов; один из худших |
| Август 2022 | ЦОД в Айове | Локально | Электрический пожар (3 пострадавших); затронуты часть сервисов, не глобально | Электрический пожар в ЦОД | Физический объект; не чисто софт/архитектура |
| Апрель 2023 | Европа (Париж и др.) | Часы | Сбои сети и сервисов в нескольких регионах | Наводнение + ЦОД + сетевые проблемы | Погодный фактор; среднее влияние |
| 23 октября 2024 | Европа (Франкфурт europe-west3) | ~12+ ч | Регион в основном недоступен; затронуты многие европейские заказчики | Подробно не раскрыто (подозрение на контрольную плоскость/сеть) | Один из самых длительных сбоев в одном регионе |
| **12 июня 2025** | **Глобально** (40+ регионов) | ~2,5–3 ч | Сбои **70+ сервисов GCP**; падение IAM → сбои API-запросов; Spotify, Discord, Twitch, Cloudflare, Fitbit, Gmail, Drive, YouTube и др. упали | **Service Control** (ядро API-аутентификации): автоматическое обновление внесло тяжёлый баг → цикл сбоев → глобальная перегрузка | **Широко признано худшим глобальным сбоем GCP с 2020 года** |
| 18 июля 2025 | us-east1 | ~2 ч | Повышенная доля ошибок у нескольких продуктов | Подробно не раскрыто | Средний масштаб; восстановление относительно быстрое |


## Сбои Azure

У Microsoft Azure с 2014 по 2025 год не было аномально большого числа **крупных инцидентов**, **широких по охвату, длительных и привлекающих внимание** (по сравнению с ранним периодом частых мелких сбоев при меньшем масштабе ситуация улучшилась). Несколько событий действительно привели к глобальному или мультисервисному влиянию, особенно когда были затронуты **Microsoft 365, Teams, Xbox, Outlook** и другие потребительские/корпоративные продукты; эффект распространения был очень заметен.

Ниже — хронологический список **крупных** сбоев Azure (по Azure Status History, Post Incident Reviews, СМИ, Wikipedia, отраслевым разборам):

| Время | Регион/охват | Длительность | Основное влияние и последствия | Основная причина | Заметки/оценка отрасли |
|-------|--------------|--------------|--------------------------------|------------------|------------------------|
| 14–18 августа 2014 | US Central, US East, US East 2, Europe North | Несколько дней, часы за событие | Cloud Services, SQL Database, VM, Websites, HDInsight, Mobile Services, Service Bus в основном недоступны | Несколько сетевых/хранилищных проблем | Самая концентрированная волна 2014 года; Azure ещё молодой |
| **18–19 ноября 2014** | **Несколько регионов** (США, ЕС, Азия) | ~11 ч | В центре Azure Storage; VM, Websites, Visual Studio Online, Xbox Live, MSN, Search, 20+ сервисов упали | Изменение конфигурации производительности хранилища → бесконечный цикл фронта Blob | **Худший ранний инцидент Azure**; детальный RCA; компенсация заказчикам |
| 15 сентября 2016 | **Глобально** | Часы | Массовый сбой разрешения DNS; затронуты многие сервисы, зависящие от Azure DNS | Глобальная проблема DNS | Обнажён риск единой точки отказа DNS |
| 20 июня 2018 | Несколько ЦОД в Северной Америке | Часы–1+ день | Сбой охлаждения (молния + защита от перенапряжения) → сбои нескольких сервисов | Физический объект (каскад от молнии) | Редкий инцидент уровня железа/инфраструктуры |
| 4 сентября 2018 | **Несколько регионов** | 25+ ч (часть сервисов 3 дня) | Ключевые сервисы длительно недоступны | Охлаждение (молния + перенапряжение) | Одно из самых длительных восстановлений |
| 23 января 2023 | **Глобально** (ядро сети) | ~3 ч | Microsoft 365 (Teams, Outlook, Exchange), часть сервисов Azure упали | Проблема WAN | «Падение» M365; огромное влияние |
| 18 июля 2024 | US Central | ~Полдня | Сбои операций управления VM и др.; заказчики не могли получить доступ к управляемым сервисам | Ошибка контроля доступа + сбой инфраструктуры | Близко по времени к глобальному BSOD CrowdStrike на следующий день, но независимо |
| 8–9 января 2025 | East US 2 и др. | Часы | Сбои сети Azure Databricks, Synapse, Functions, App Service, VM | Проблема сетевого компонента | Заметный инцидент начала 2025 года |
| **29 октября 2025** | **Глобально** | ~8 ч | В центре Azure Front Door; Microsoft 365, Outlook, Teams, Xbox Live, Minecraft, Copilot упали; затронуты Alaska Airlines, Heathrow, Costco, Starbucks и др. | **Изменение конфигурации Azure Front Door** + баг защиты → несовместимая конфигурация распространилась глобально | **Худший инцидент Azure в 2025 году**; Downdetector 30k+ отчётов; похоже на сбой AWS в том же месяце |
| 5–6 ноября 2025 | West Europe (AZ01) | ~9–10 ч | Деградация/остановка VM, PostgreSQL/MySQL Flexible Server, AKS, Storage, Service Bus | Тепловой инцидент в ЦОД | Серьёзный региональный сбой |

### Наблюдения и тренды (2014–2025)

- **2014**: Azure в фазе быстрого роста; частые проблемы **изменений конфигурации** и **слоя хранилища**; самый концентрированный по сбоям год (ноябрьский инцидент — классический кейс).
- **2015–2019**: Частота сбоев снизилась; по-прежнему в основном **один регион** или **инфраструктура** (охлаждение, молния, DNS); влияние относительно ограничено.
- **2020–2023**: Крупных глобальных сбоев мало; чаще **сеть** или **зависимость M365 от Azure** (напр., январь 2023).
- **2024–2025**: Контрольная плоскость/край (напр. **Azure Front Door**) стал новой болевой точкой; 29 октября 2025 широко признано худшей **глобальной остановкой** Azure за последние годы, сопоставимой с Alibaba ноябрь 2023 или GCP июнь 2025.
- **Типичные черты**: Детальный **Post Incident Review (PIR)** после крупных инцидентов; **изменение конфигурации**, **контрольная плоскость**, **сеть** часто в корне (не только железо); сильное распространение на третьи стороны при сбоях M365, Xbox, Teams; компенсация по SLA (кредит); заказчики больше всего заботятся о непрерывности бизнеса.

В целом у Azure за 2014–2025 порядка **8–10** **крупных** (глобальных/мультисервисных, длительных) сбоев; тяжесть и частота на одном уровне с AWS и GCP; **каскадный сбой из-за ошибки конфигурации** — повторяющийся сценарий.


## Сбои Cloudflare

Cloudflare как один из крупнейших в мире CDN, безопасности, DNS и edge-провайдеров с 2014 по 2025 год не имел аномально большого числа **крупных инцидентов**, вызвавших **широкий сбой интернета**. Когда они происходили, влияние достигало **миллионов и сотен миллионов** пользователей (Cloudflare обрабатывает ~20–25% мирового веб-трафика).

Типичная картина: **восстановление часто быстрое** (большинство ослабевает за 1–4 ч), но **распространение крайне сильное** — при сбое ядра прокси, DNS или компонентов безопасности многие топовые сайты (X, ChatGPT, Shopify, Discord, Spotify, части AWS и т.д.) одновременно получают 5xx или становятся недоступны.

Ниже — хронологический список **крупных** сбоев Cloudflare (по официальному блогу, истории status.cloudflare.com, СМИ, Wikipedia; фокус на глобальных/ядровых трафиковых событиях):

| Время | Охват | Длительность | Основное влияние и последствия | Основная причина | Заметки/оценка отрасли |
|-------|-------|--------------|--------------------------------|------------------|------------------------|
| **2 июля 2019** | **Глобально** | ~1–2 ч | Массовые 502/503/504 на сайтах; большие части интернета недоступны | Внедрение софта внесло тяжёлый баг → падение слоя прокси | **Широко признано худшим за всю историю Cloudflare**; детальный разбор |
| 2020, несколько раз | Часть регионов/контрольная плоскость | Часы | Недоступны дашборд, аналитика, часть API; ядро прокси в основном стабильно | Проблемы контрольной плоскости | Больше влияния на разработчиков; обычные пользователи меньше замечают |
| Июнь 2022 | **Несколько ЦОД** (19) | ~1,5 ч | Остановка ядра прокси; множество сайтов недоступны | Ошибка конфигурации сети | Средний масштаб; быстрое восстановление |
| 21 марта 2025 | **Глобально** | ~1 ч 7 мин | Сильные сбои чтения/записи хранилища; затронуты многие сервисы, зависящие от хранилища/кэша | Сбой записи слоя KV/хранилища + частичные проблемы чтения | Заметный инцидент начала 2025 года |
| 12 июня 2025 | **Глобально** (часть функций) | Часы | Часть функций/сервисов недоступна; ядро трафика в основном в порядке | Внедрение определённого модуля | Не остановка ядра трафика; ограниченное влияние |
| 14 июля 2025 | **Глобально** (DNS 1.1.1.1) | ~62 мин | Публичный DNS-резолвер (1.1.1.1) полностью недоступен; многие пользователи не могли выйти в интернет | Ошибка конфигурации → отзыв BGP-маршрута → префикс DNS исчез из глобальной таблицы маршрутизации | **Очень тяжело для пользователей 1.1.1.1**; уровень «обрушения интернета» |
| ~Октябрь 2025 | Часть сервисов | Десятки минут | Краткий сбой разрешения DNS | Проблема конфигурации DNS | Средний масштаб |
| **18 ноября 2025** | **Глобально** | ~4–5 ч (пик дольше) | **Крупная остановка интернета**: X (Twitter), ChatGPT, Shopify, Spotify, Letterboxd, Indeed, Canva, Uber, DoorDash, Truth Social, League of Legends и др.; ~20% веб-трафика; 1/3 сайтов из топ-10k Alexa | Аномальный рост файла правил Bot Management (изменение прав БД → удвоение размера файла) → глобальное распространение → падение прокси | **Худший в 2025 году**; также худшая глобальная остановка трафика с 2019 года |
| 5 декабря 2025 | **Глобально** | Часы | Снова массовые 5xx; затронуты Shopify, Zoom, Vinted, Fortnite, Square, Just Eat, Canva, Vimeo, части AWS, Deliveroo и др. | Полной официальной первопричины нет (подозрение на конфигурацию/распространение) | **Всего через 17 дней после 18 ноября**; два крупных инцидента подряд вызвали сильную критику |

### Наблюдения и тренды (2014–2025)

- **2014–2018**: Cloudflare быстро рос; публичных **крупных глобальных** инцидентов мало; в основном локальные/региональные/функциональные проблемы; зависимость интернета от Cloudflare была ниже, чем сейчас.
- **Июль 2019**: Стал классическим «чёрным лебедем» Cloudflare; более шести лет не было **глобальной остановки ядра прокси** сопоставимого масштаба.
- **2025 как аномальный год**: Не менее **3–4** широких глобальных/почти глобальных событий (особенно 18 ноября и 5 декабря подряд). **18 ноября** широко признано **худшим с 2019 года**. 5 декабря снова заставило многих усомниться в контроле изменений, откате и принципе «fail small».
- **Типичные черты**: Большинство тяжёлых инцидентов связаны с **изменением конфигурации**, **правилами/распространением**, **контрольной плоскостью** или **DNS/BGP**; очень прозрачные разборы на blog.cloudflare.com; восстановление обычно быстрое (откат + остановка распространения), но влияние очень широкое (Anycast + механизм вызова); нет явной компенсации по SLA как у AWS/Azure/Google, но есть детальные объяснения и обязательства по улучшениям.

В целом у Cloudflare за 2014–2025 порядка **5–7** **крупных** (глобальная ядровая трафиковая, длительная) сбоев; **июль 2019** и **18 ноября 2025** — два пиковых события. В 2025 году частота сбоев заметно выросла, возобновилось обсуждение «риска концентрации интернет-инфраструктуры».


## Сбои Tencent Cloud

Tencent Cloud с 2014 по 2025 год как второй по размеру публичный облачный провайдер Китая (после Alibaba Cloud) имел в целом хорошую стабильность среди местных провайдеров. Действительно **широких, длительных, привлекающих внимание глобальных/мультирегиональных крупных** инцидентов было относительно немного; при сбое контрольной плоскости (консоль/API) или ключевого хранилища влияние быстро распространялось на множество предприятий и разработчиков.

**Страница статуса** Tencent Cloud (https://status.cloud.tencent.com/history) относительно непрозрачна: история часто показывает только последний год, многие средние и крупные инциденты отсутствуют; полная картина складывается из официального WeChat, техблога, СМИ и сообщества.

Ниже — хронологический список **серьёзных, широких по охвату** инцидентов Tencent Cloud (по официальным разборам, СМИ, Zhihu/Weibo/сообществу разработчиков):

| Время | Регион/охват | Длительность | Основное влияние и последствия | Основная причина | Заметки/оценка отрасли |
|-------|--------------|--------------|--------------------------------|------------------|------------------------|
| 2 ноября 2014 | **По стране** (контрольная плоскость + часть сервисов) | ~6 мин | Медленный сайт Tencent Cloud, сбой загрузки изображений, сбой консоли; часть пользователей не могла нормально пользоваться | Подробно не раскрыто (подозрение на сеть/нагрузку) | Ранний период малого масштаба; влияние ограничено, но тогда широко освещено |
| Август 2018 | Часть пользователей/облачный диск | Неясно (влияние на одного пользователя часы до постоянного) | **Обнуление/потеря** данных облачного диска у нескольких пользователей; убытки порядка десятков миллионов | Тихий сбой диска + сбой проверки/реплики при миграции | **Худший инцидент «потери данных» в истории Tencent Cloud**; кризис доверия; детальный разбор |
| 2023 (отдельные сообщения) | Часть регионов/сервисов | Десятки мин–часы | Отдельные сбои консоли/API, джиттер хранилища | Детального публичного разбора нет | По сравнению с глобальным сбоем Alibaba в ноябре 2023 Tencent был относительно стабилен |
| **8 апреля 2024** | **17 регионов глобально** | ~74–87 мин | Консоль полностью недоступна; облачный API 504 Gateway Timeout; инстансы CVM/RDS работают, но управление/продление/масштабирование невозможно; 1957 обращений заказчиков | Обратная несовместимость новой версии API + отсутствие механизма поэтапного раскрытия конфигурации → полный выкат → глобальное распространение | **Самый тяжёлый за последние годы у Tencent Cloud**; широко названо «глобальной аварией», «обрушением контрольной плоскости»; стиль похож на Alibaba ноябрь 2023 |
| 15 октября 2025 | Несколько регионов | ~Десятки мин–1 ч | Сбои Auto Scaling и других сервисов | Подробно не раскрыто | Со страницы статуса; средний масштаб |
| 17 октября 2025 | Гуанчжоу | ~1+ ч | Сбои сервисов, связанных с AI digital-human | Подробно не раскрыто | Региональный; конкретный продукт AI/цифровой человек |

### Наблюдения и тренды (2014–2025)

- **Ранний период (2014–2018)**: Сбои часто **потеря данных хранилища** или **краткие проблемы доступа**; инцидент «потери данных» 2018 года сильнее всего ударил по доверию предприятий.
- **2019–2023**: Частота и тяжесть сбоев Tencent Cloud снизились; общенациональных/глобальных событий мало; стабильность выше, чем у Alibaba в тот же период (напр., спокойно во время 11·12 у Alibaba).
- **2024–2025**: 8 апреля 2024 стало переломным; **глобальный сбой контрольной плоскости** заставил многих переоценить «безопасность изменений» и «поэтапный выкат». В 2025 было несколько средних инцидентов, но ничего уровня «полная остановка сервисов» как в апреле 2024 или у Alibaba/Google.
- **Типичные черты**: **Контрольная плоскость/API** — главная болевая точка (апрель 2024); **хранилище/потеря данных** наиболее разрушительны для предприятий (2018); разборы относительно своевременны (WeChat, техсообщество); нет строгой компенсации по SLA как у AWS/Azure/Google, но есть ваучеры/компенсация; распространение сбоя менее драматично, чем у Alibaba/Cloudflare (клиентская база более корпоративная/игры/видео, меньше зависимость от потребительского интернета).

В целом у Tencent Cloud за 2014–2025 порядка **3–5** **крупных** (общенациональная/глобальная контрольная плоскость длительно недоступна или серьёзная потеря данных) инцидентов; **потеря данных 2018** и **глобальный сбой контрольной плоскости 8 апреля 2024** — два самых обсуждаемых.


## Прозрачность по сбоям

С точки зрения прозрачности по сбоям Alibaba Cloud и Tencent Cloud относительно слабы.

Доска статуса Alibaba Cloud (https://status.aliyun.com/#/?region=cn-shanghai) и Tencent Cloud (https://status.cloud.tencent.com/history) показывают только события за последний год.

Azure (https://azure.status.microsoft/en-us/status/history/) хранит пять лет. Cloudflare (https://www.cloudflarestatus.com/history?page=17) наиболее прозрачен; можно листать страницы назад на несколько лет.


## «Смерть» публичного облака

В молодости я любил читать и рефакторить чужой код. Пока «Java Boy» не преподал урок: даже после того, как я починил утечку памяти, он почувствовал глубокий экзистенциальный кризис. Гневом он прикрывал собственную несостоятельность и возлагал вину за «поддержание стабильности платформы Kubernetes» на меня.

Я и сам не горел желанием за ним убирать. Просто частые алерты `OOM kill` меня раздражали. Из той истории я вынес философию нуля: **рефакторинг с нулевой предельной выгодой никому не нужен.**

Отсюда **закон возрастания энтропии** в софте: кодовую базу проекта со временем ожидает превращение в «свалку».

Кто-то спросил: какое это имеет отношение к «смерти» публичного облака?

Прямое. Потому что «индустриальный Ктулху» требует от компаний растущей прибыли. Поэтому для провайдеров публичного облака и их рядовых сотрудников необходимо «рассказывать новую историю роста» — в 2026 году эта история про AI.

Старый код просто гниёт. Менять его — нулевая предельная выгода.

И все сходятся в одном: не трогать чужой код, дать ему превратиться в свалку. И с кодом так, и с архитектурой. Даже когда сетевая топология — чистая сеть взаимных зависимостей, при сбое все одинаково без сервиса, и когда ответственность за простой распределена поровну, на тебе лично ответственности нет.

Ирония в том, что инженера по эксплуатации с нулём инцидентов за время работы, который «каждый день спит на работе», сочтут некомпетентным — потому что выглядит, будто он ничего не делает. Контринтуитивно: такого человека стоило бы держать как талисман компании — неизвестно, сколько он сделал раньше ради стабильности. Или ему просто повезло, и он заслуживает алтаря.

Лучшая эксплуатация — не эксплуатировать. Потому что **доход от эксплуатации и карьерный риск совершенно несоизмеримы**. Начальник не доплатит за удаление «вроде бы ненужной» настройки; но за удаление нужной настройки БД тебя обругают заказчики.

Провайдеры публичного облака забывают: сетевой эффект может их поднять и может больно опустить. Чем больше у них заказчиков, тем сильнее сетевая цепная реакция от одного простоя. Как сбой Alipay 4 декабря 2025, ~21:00–23:37 — уже шестой крупный инцидент экосистемы Alibaba в 2025 году.

Когда масштаб пользователей — сотни миллионов, каждую секунду кто-то платит. А бизнес продолжает требовать новые функции; в конце концов система не выдерживает.

И компенсация провайдеров публичного облака совершенно несоизмерима. Для чего-то вроде Alipay это максимум «вернуть разницу»; недобор считают подарком. Но потери госсектора и предприятий не поддаются оценке. Если твой бизнес на публичном облаке и облако легло — как ты объяснишь провайдеру свой ущерб?

«Моя система обрабатывает миллиарды транзакций в день; вы мне компенсируете пару миллиардов?»

Ущерб заказчика не квантифицируем, поэтому Alibaba Cloud обычно просто раздаёт ваучеры. Это капля в море. Никто не может толком учесть потерянное время, реальное влияние на бизнес и ценность этого времени.

Сетевой эффект принёс публичному облаку экспоненциальный рост выручки. Для крупных государственных и корпоративных пользователей **антизависимость** от одного публичного облака должна быть в повестке. Связать свою судьбу с одним облачным провайдером — нельзя справиться с внезапным риском.


## Системы малой параллельности и высокой доступности

На этой основе я предлагаю «системы малой параллельности и высокой доступности»: **избыточность хранилища** для **высокой доступности** бизнеса.

Когда трафик распределён по избыточным системам, ты избегаешь пика трафика одного кластера при централизованном потоке и сокращаешь радиус распространения сбоя.

Простейший пример: при разрешении DNS направлять Гуандун на кластер Kubernetes Alibaba + Tencent в Южном Китае. Каждый кластер независим и крутит полную внутреннюю бизнес-систему. В худшем случае при сбое самого публичного облака недоступность не более 50%.

Одновременная недоступность обоих крайне маловероятна.


## 孤帆远影碧山尽，唯见长江天际流  
Прощай, облачный сервис. Увидимся на Янцзы.


## Ссылки

【1】  
Сбой сервисов Cloudflare 18 ноября 2025  
https://blog.cloudflare.com/zh-cn/18-november-2025-outage/

【2】  
Невидимое влияние DNS на примере сбоя AWS: как DeepFlow быстро нашёл первопричину в хаосе  
https://my.oschina.net/u/3681970/blog/18697034

【3】  
Разбор и анализ сбоя Alibaba Cloud 2023-11-12  
https://github.tiankonguse.com/blog/2023/11/29/aliyun-break.html
