[5 лет назад](https://www.bullshitprogram.com/the-seed-of-robot/), я сравнил AI с интеллектуальным API-шлюзом, предложив подход "разделяй и властвуй" для преобразования большой проблемы в несколько решаемых маленьких проблем.

```go
func sum(arr []int) int {
    if len(arr) == 1 {
        return arr[0]
    }
    mid := len(arr) / 2
    leftSum := sum(arr[:mid])
    rightSum := sum(arr[mid:])
    return leftSum + rightSum
}
```

Как рекурсивная функция суммирования выше — разделить массив пополам и рекурсивно суммировать каждую часть.

Сегодня эта идея продолжается в протоколе [MCP](https://modelcontextprotocol.io/introduction).

В период 2025-04 я использовал `cline` с `Google gemini` в качестве базовой большой модели "ядро" для изучения полного протокола вызова MCP большими языковыми моделями.

Но в настоящее время реализация MCP всё ещё несколько уродлива и имеет некоторые проблемы.
И из-за проблем самих больших моделей это приводит к избыточному потреблению токенов.

## Текущее состояние

Протокол MCP имеет встроенную систему обнаружения сервисов. Каждый MCP-сервер регистрирует свою реализацию и методы вызова, затем добавляет их в подсказки при вызове, как параметры для запроса удалённых AI-серверов, позволяя AI найти правильные команды и затем выполнить их локально.

Например, [Gemini Function Call](https://ai.google.dev/gemini-api/docs/function-calling?hl=zh-cn) выглядит примерно так:

```bash
curl -X POST "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "tools": [
      {
        "function_declarations": [
          {
            "name": "get_current_weather",
            "description": "Get the current weather for a given location",
            "parameters": {
              "type": "object",
              "properties": {
                "location": {
                  "type": "string",
                  "description": "The city and country, e.g. Shanghai, China"
                }
              },
              "required": ["location"]
            }
          }
        ]
      }
    ],
    "contents": [
      {
        "parts": [
          {
            "text": "What is the weather in Shanghai right now?"
          }
        ]
      }
    ]
  }'
```

Весь процесс может быть очень сложным. Например, когда мы приказываем AI "удалить все скриншоты на рабочем столе", идеальная команда:

```bash
find /Users/zeusro/Desktop -type f -name "Screenshot*.png" -delete && find /Users/zeusro/Desktop -type f -name "Screenshot*.jpg" -delete
```

Но фактический процесс выполнения может быть:

1. Найти все файлы на этом пути, получить соответствующие пути
1. Удалить скриншот изображение 1
1. Удалить скриншот изображение 2
1. Удалить скриншот изображение n

![image](/img/in-post/mcp-limitation//传统ai问路.png)

Этот процесс вычисления зависит от собственных возможностей большой модели. Если это что-то вроде gemini-2.0, это первый случай, напрямую одним шагом. Другие отечественные модели в основном не предлагают бесплатные API, поэтому я в основном не использую их.

```bash
input --> process --> output --> (оценить) влияние, рассмотреть, выполнять ли следующее вычисление
```

Люди, как внешние наблюдатели, оценивают, наблюдают влияние вычислений, дополняют подсказки, побуждают AI продолжать вычисления, постоянно исправляя, пока не получится окончательный результат.

```zeusro
func 计算(){
    ai.找到合适的工具链调用()
    （可选）用户.评估潜在影响并决定是否要执行相应命令
    ai+mcp client(通常可以在ai客户端里面顺便集成mcp功能，比如vs code cline插件).调用mcp server()
    （可选）用户.评估最终影响()
        if 满足需求（）{
            return
            }
        else{
            用户.补充提示词，继续向ai提问()
            计算()
        }
}
```

С точки зрения управления проектами кода, отношения между AI и людьми похожи на "разработчик" и "рецензент", где рецензенты решают, "сливать" ли код.

## local function и cloud function

В 2020 году я использовал вызов такси в качестве примера, чтобы предложить `Cloud Function`.

`Cloud Function` относится к функции, которая полагается на облачные программные и аппаратные ресурсы для выполнения вспомогательных вычислений.

Соответствующей `Cloud Function` является `Local Function`.

`Local Function` относится к функции офлайн-вычислений.
В узком смысле `Local Function` может выполняться без сети, обычно понимается как API операционной системы; в широком смысле `Local Function` относится к локальным функциям локального оборудования.
Как получение пекинского времени на мобильном телефоне — хотя телефон имеет встроенные часы, время нужно периодически синхронизировать из Национального центра времени.

Это немного похоже на будильник дома — хотя он может работать с батареями, из-за дрейфа времени нам также нужно регулярно вручную калибровать время.

## Разделение `local function call` и `cloud function call`

![image](/img/in-post/mcp-limitation/远程本地函数分离.png)

Но, на мой взгляд, текущая реализация протокола MCP может считаться только вторым выбором (переходным решением).
На самом деле, я думаю, что на данном этапе более необходимо "разделение функций", разделение функций на `local function call` и `cloud function call`. Для `local function call`,
это может даже выполняться без сети, как "открыть xx приложение", "отправить текст бабушке", такие потребности вообще не нуждаются в облачных функциях, "офлайн-вычисления" могут с ними справиться.

AI должен иметь подготовленную базу знаний, со встроенными поддерживаемыми API при работе с разными операционными системами, а не как сейчас, где даже удаление файла требует создания [file-system](github.com/modelcontextprotocol/servers/tree/main/src/filesystem) для реализации.

На самом деле, точки входа AI крупных отечественных систем реализованы именно так. Через xx-ассистент, анализируя голосовые команды пользователя, переводя их в конкретные подзадачи, которые нужно выполнить.

## Заключение

Протокол MCP, как переходный дизайн, действует несколько как установление стандарта `app store` для AI API (язык/OS-независимые интерфейсы для AI). После завершения этой задачи его можно вывести из эксплуатации.

![image](/img/in-post/mcp-limitation/ps.gif)
