# 教育行政化体系下における激励関数の設計

## はじめに

本稿は教育行政化体系をマクロな背景として、(1)教師Y・F・D、(2)生徒ユダ・ブラックマンバ・P・Y・C13、(3)心理教師、(4)学校領導の家庭環境・性格・行動パターンを抽出する。「人間の意思決定」を計算可能な変数→スコア→確率/結果に分解し、異なる決定の政策リスクと結果を分析し、役割ごとの最適戦略を検討し、学校領導のための時間激励関数を可能な限り設計する。

## 形式論理と定義

**教育行政化**：生徒は教師に、教師は校長に、校長は学校に責任を負う。学校の業績は生徒の平均成績と本科進学率で定量化される。

**蹴り猫効果**（Kick the cat、蹴り犬効果）[1]：組織や家庭で上位者が下位者を罰して不満を転嫁し、下位者も同様にさらに下位に伝播させる連鎖の比喩。

**利得関数**：教師の利得は生徒の平均成績と本科進学率。生徒の利得は個人の大学入試成績。最終成績は過去3年の成績と正の相関。

## 利得（Payoff）の定義

- **教師利得** \(U_{\text{teacher}}\)：生徒平均成績 \(\bar{S}\) と本科進学率 \(r\) を変数とする  
  \[
  U_{\text{teacher}} = w_{\text{avg}} \cdot \bar{S} + w_{\text{enroll}} \cdot r
  \]  
  実装では \(w_{\text{avg}}=0.6\)、\(w_{\text{enroll}}=0.4\)。業績（領導層の激励）は教師利得と同型。

- **生徒の入試成績予測** \(G\)：過去3年の年末成績と正の相関、近年ほど重み大  
  \[
  G = w_1 S_{t-3} + w_2 S_{t-2} + w_3 S_{t-1},\quad w_1+w_2+w_3=1,\; w_1\le w_2\le w_3
  \]  
  実装では \(w_1=0.2,\,w_2=0.3,\,w_3=0.5\)。

- **生徒利得** \(U_{\text{student}}\)：個人の入試成績（予測値）が利得。受験プール外なら入試利得なし  
  \[
  U_{\text{student}} = \begin{cases} G & \text{受験プールに在籍時} \\ 0 & \text{それ以外} \end{cases}
  \]

## 定量公式

公式1：生徒平均成績 = 生徒総得点 / 生徒数

公式2：本科進学率 = 本科合格者数 / 受験者数 × 100%

## 人物モデリング

**教師Y**：公式1を意思決定の根拠とする。公式1の生徒数を減らせる（PUA戦略で休学・退学させる）。罰則・保護者連絡・班会での公開名指し批判で生徒数を減らす。嘘と監視回避で上級の道徳・法審査に対応。

**教師F**：公式1・2を根拠とする。公式1の生徒数は変えず、本科進学率のため受験者数を減らせる。

**教師D**：公式1・2を根拠とする。平均成績の最大化を目指すが、生徒の排除は行わない。

**生徒ユダ**：富裕な中産階級。教師Fに取り入って群管理を獲得。ネットいじめで他生徒を攻撃し、人数削減を図る。

**生徒ブラックマンバ**：非常に裕福。マカオ科技大学などの本科を「金の力」で購入可能。受験は選択肢の一つで、受験しないこともある。

**生徒P**：学力・IQが低い。教師YのPUAに対して回避的態度を取り、休学で消極的抵抗。

**生徒Y**：強度近視の高IQアスリート。入試でスポーツ加分を利用。加分は学校領導の承認が必要。

**生徒C13**：貧しい家庭だがIQ>160の天才。

**心理教師**：システムのバランサー。生徒の心理圧力と負の感情を軽減。

**学校領導**：資源配分（誰に加分、誰を休学・退学させるか）、心理教師の個別指導割り当てを担当。

時系列メタプログラミングモデルで家庭背景・IQ・EQ・PUA・法規・道徳リスクなどを定量化し、役割ごとにエージェントをモデル化して戦略と結果をシミュレート。実装はGo、`function/local/n/china/shantou/` に配置。

## 時系列メタプログラミングモデル（function/time.md と整合）

- **第一原理**：時間が第一次元。時系列オブジェクトの第一メンバは時間、時系列関数の第一引数は時間。
- **時系列オブジェクト**：`Factor`、`Agent`、`SimState` は `Birth` または `Current` を第一メンバに持つ。
- **時系列関数**：`Incentive(t, ...)`、`ChooseStrategy(t, ...)`、`ApplyStrategy(t, ...)` は時間 `t` を第一引数に取る。
- **時系列ログ**：全イベントは「時間＋内容」形式（`LogTS`）。
- **可視化**：激励を `(t, 業績値)` でサンプリングし、時間をx軸にプロット。

## 量化因子の定義

| 因子 | 記号/フィールド | 範囲 | 意味 |
|------|-----------------|------|------|
| 家庭背景 | FamilyBackground | [0,1] | 0=極貧、1=極富。資源と進路（金の力・アスリート投資）に影響 |
| 知能 | IQ | [0,1] | スコアに写像。学業と戦略理解に影響 |
| 情動知能 | EQ | [0,1] | 耐圧性と蹴り猫連鎖の感情伝播に影響 |
| PUA暴露 | PUAExposure | [0,1] | 教師のPUAが当該個体に及ぶ強度 |
| PUA耐性 | PUAResistance | [0,1] | PUAへの耐性 |
| 法規・道徳リスク | LegalMoralRisk | [0,1] | 個体/行為が引き起こす追及リスク |

純PUA圧力：`PUAExposure × (1 - PUAResistance)`。休学・回避戦略の駆動に使用。

## 役割と戦略モデリング

| 役割 | 激励の根拠 | 選択可能な戦略 | 選択ロジック（概要） |
|------|------------|----------------|----------------------|
| 教師Y | 公式1（平均） | PUA減員・嘘/回避・通常授業 | 平均低かつ人数多→PUA；法リスク高→嘘/回避 |
| 教師F | 公式1+2 | 受験者削減・嘘/回避・通常授業 | 受験者多かつ進学率低→受験者削減 |
| 教師D | 公式1+2 | 嘘/回避・通常授業（排除なし） | 法リスク高→嘘/回避；否則通常授業 |
| 生徒ユダ | 教師Fに取り入る | ネットいじめ・勉強 | 人数多かつ自身の法リスク低→いじめ |
| 生徒ブラックマンバ | 金の力 | なし（受験不参加） | — |
| 生徒P | 低IQ・高PUA暴露 | 休学・退学・回避 | 純PUA高かつ圧力大→休学 |
| 生徒Y | スポーツ加分 | スポーツ加分 | 安定：加分選択 |
| 生徒C13 | 高IQ・貧困 | 勉強 | 安定：勉強 |
| 心理教師 | システム平衡 | 減圧・安抚 | 平均圧力高→減压 |
| 学校領導 | 業績=激励 | 下への圧力・激励設計 | 業績低→圧力（蹴り猫）；高→激励設計 |

## 戦略と結果の定量化

| 戦略 | 結果（増分/ブール） | 対象 |
|------|---------------------|------|
| PUA減員 | ΔStress↑, LegalRisk↑ | ランダム対象生徒 |
| 受験者削減 | LeaveExam, LegalRisk↑ | ランダム対象生徒 |
| 嘘/監視回避 | LegalRisk↓（短期） | 行為者 |
| 休学・退学 | Dropout, LeaveExam | 本人 |
| ネットいじめ | ΔStress↑, LegalRisk↑ | ランダム対象生徒 |
| スポーツ加分/勉強/回避 | ΔScore, ΔStress | 本人 |
| 減压・安抚 | ΔStress↓ | ランダム対象生徒 |
| 下への圧力 | ΔStress↑ | ランダム対象生徒 |

## 時間激励関数

業績（領導層が知覚する激励）は教師利得と同型。時間 \(t\) の関数として：

```
Incentive(t) = TeacherPayoff(平均成績, 本科進学率) = 0.6 × 平均成績 + 0.4 × 本科進学率
```

平均成績と進学率は、時刻 \(t\) の在籍者・受験者・合格者から計算。各ステップで `Incentive(t)` をサンプリングし「時間–業績」曲線を描く。入試成績予測は毎年末に `ScoreHistory`（過去3年）で更新し、`GaokaoScore` と `StudentPayoff` に用いる。

## ナッシュ均衡と各主体の最適戦略

上記利得と戦略空間のもとで、均衡と推奨（シミュレーションと理論は一致）：

| 役割 | 利得/目標 | ナッシュ下の戦略 | 最適戦略の提案 |
|------|-----------|------------------|----------------|
| **教師** | \(U_{\text{teacher}}=\bar{S}\) と進学率 | 平均低かつ人数多→PUA/受験者削減（裏切り）；法リスク高または前回裏切り→通常授業（協力） | 繰り返し博弈では主に通常授業で評判維持；平均が明らかに低く人数が多いときのみ減員を検討し、法・道徳リスクに注意 |
| **生徒** | \(U_{\text{student}}=G\)（3年相関） | 高IQ・低PUA→勉強；高PUAかつ圧力大→休学または回避 | 3年成績の最大化を主に：優先は「勉強」；高圧力・高PUA時は「回避」または必要なら休学で長期利得を守る |
| **心理教師** | システム安定（総圧力低減） | 平均圧力が閾値超で減压・安抚、否則無行動 | `AvgStress > 閾値` のとき減压、それ以外は無行動 |
| **学校領導** | 業績 = \(U_{\text{teacher}}\) | 業績が閾値未満で下へ圧力（蹴り猫）；否則激励設計 | 低→圧力；高→激励設計・加分承認・資源配分 |

**ナッシュの要点**：教師と生徒は繰り返し博弈の関係。教師が長期に裏切り（PUA/受験者削減）すると生徒の報復（いじめ等）や回避・休学を招き、平均成績と進学率を損ない教師自身の利得も下がる。均衡では教師は多く通常授業、生徒は極端な圧力がなければ勉強し、双方が長期で利得最大化に近づく。心理教師と領導は集約指標（平均圧力・業績）に応じた閾値反応が最適。

## シミュレーション実験設計

- **ステップ**：日単位（または設定可能）で進行。
- **各ステップ**：現状態で集約指標（生徒数・受験者数・進学率・平均圧力等）を更新し、在籍メンバーごとに役割で `ChooseStrategy(t, agent, ctx)` を呼び、得た戦略で `ApplyStrategy(t, strategy, ...)` を呼んで結果を適用し、「時間+内容」ログを追加。
- **出力**：① 時系列ログ；② 激励サンプル（時間→業績）；③ 終状態統計（在籍数・受験者数・本科合格数・平均成績・進学率・業績）。

実行：当該ディレクトリで `go run .` または `go build` 後に実行ファイルを実行。

## 実装ファイル（同ディレクトリ）

| ファイル | 内容 |
|----------|------|
| `model.go` | 時系列型：Factor, Event, Point, NLine。時間第一メンバ（Birth/T） |
| `roles.go` | Role・Strategy 列挙。Agent（Birth第一）、NewAgent。Factor, InSchool, InExamPool, Score, ScoreHistory, Stress, LegalRisk, StrategyCount, LastStrategy |
| `incentive.go` | IncentiveParams。Incentive(t,...), IncentiveAt。TeacherPayoff。GaokaoScore(ScoreHistory)。StudentPayoff |
| `strategy.go` | ChooseStrategy(t, agent, ctx) を役割で分派。Consequence。ApplyStrategy(t, strategy, ...) |
| `sim.go` | SimContext, SimState。LogTS, UpdateContext, Run。pickStudentTarget |
| `y.go` | メイン入口 Y(...)。newNamedAgents。ログ・激励サンプル・終状態・C13アドバイスを出力 |
| `y_test.go` | TestY（本番長、-shortでスキップ可）。TestY_shortParams, TestY_shortRun |

## 参考

[1] 蹴り猫効果（Kick the cat）— [https://en.wikipedia.org/wiki/Displaced_aggression](https://en.wikipedia.org/wiki/Displaced_aggression)
