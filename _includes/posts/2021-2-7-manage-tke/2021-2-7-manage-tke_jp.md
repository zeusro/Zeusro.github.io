2018年半ばに`kubernetes`に触れ始め、従来のアプリケーションのコンテナ化への変換を主導しました。

実装中に遭遇した実際の問題と、対応するトラブルシューティングの経験を組み合わせて、TKEクラスターをより適切に管理する方法について説明します。

## クラスター管理

実際、TKEを使用する前に、自分に質問すべきです。この質問は~~嵐に直面する準備はできていますか~~？いや、それは：あなたは本当に`kubernetes`に適していますか？

![image](/img/in-post/manage-tke/wind.jpg)

`kubernetes`に初めて遭遇したとき、自動スケーリング、アプリケーションの自己回復、迅速な反復、バージョンロールバック、負荷分散などの機能に深く魅了されました。しかし、しばらく使用した後、アプリケーションパフォーマンス監視、ノード障害、ネットワーク診断に苦しめられました。

最も印象的だったのは、JAVA開発者がこのように私を問い詰めたときでした：「私のアプリケーションはローカルとクラウドサーバーで正常に動作していますが、コンテナ化後に遅くなるのはなぜですか？**これはすべてあなたの問題です。**」

その後、意図的に時間を費やし、このJAVAアプリケーションを長時間監視し、OOM killと応答が遅い原因を見つけ、土曜日を費やしてメモリリーク—この**コード問題**—を修正し、世界がようやく以前の平和に戻りました。

はい、これは`kubernetes`の問題ではなく、これも`kubernetes`の問題です。ソフトウェア設計には常に**「銀の弾丸はない」**という言葉があります。いわゆる便利さは、複雑さを別の場所に移すだけです。アプリケーションの最終的な一貫性は、さまざまな`Controller`の調整に依存し、いわゆる負荷分散はすべてのノードに広がるさまざまなiptableルールであり、アプリケーションの再起動はノード上の勤勉な`kubelet`に依存します。

したがって、コンテナ化がもたらす新しい課題に直面する勇気がない場合、またはアプリケーションの規模が非常に小さく、反復頻度が低い場合、これらの泥だらけの水域に足を踏み入れることはお勧めしません。

![image](/img/in-post/manage-tke/hammer.png)

「**ハンマーを持っていると、すべてが釘のように見える。**」これは治療が必要な病気です。真の戦士だけが人生の厳しい現実に直面する勇気があります。

### クラスター計画

備えあれば憂いなし。クラスターのデプロイメントに関して、私たちの[公式ドキュメント](https://cloud.tencent.com/document/product/457/11741)は実際にはかなり詳細です。クラスター計画の重要な側面は、**コンテナランタイム**と**ネットワークプラグイン**の選択にあります。

個人的には、ビジネスの観点から、`containerd`は`docker`よりわずかに優れていると思います。GoogleとDocker Inc.は異なる利益を持っているためです。`kubernetes`は最初からCRIの形式でコンテナランタイム標準を確立し、dockerを直接使用するのではなく、このアクションには意味があります。伏線は、kubernetes 1.20がdockerのサポートを廃止することです。

ネットワークプラグインについては、プラットフォームとアプリケーションの特性によって異なります。Tencent Cloudを例にとると、現在`GlobalRouter`と`VPC-CNI`をサポートしています。簡単に言えば、`VPC-CNI`はより優れたネットワークパフォーマンスを持っていますが、マシンコア数によって制限されます。アプリケーションが主に小さなマイクロサービス（メモリ使用量1G以内）である場合、`GlobalRouter`を使用する方が適切です。

さらに、コンテナネットワークのCIDRも痛みのポイントです。CIDR範囲が小さすぎる場合、割り当て可能なpod/service IPが少なすぎ、最終的なアプリケーション規模にも影響します。

### 災害復旧計画

かつて、私の前に美しい`namespace`が置かれていましたが、大切にしませんでした。誤って削除して、すべてが手遅れであることに気づくまで。天がもう一度チャンスを与えてくれるなら、その時私の脳が水浸しになっていなかったことを本当に願います。

![image](/img/in-post/manage-tke/tear.jpeg)

その事件を今でも覚えています。全体的なビジネスの可用性を回復するために、技術部門の半分が非常に遅くまで残業しなければなりませんでした。しかし、回復プロセス中に、以前の作業が不十分だった領域を実際に発見しました：例えば、開発者に特定の`namespace`内のリソースを変更する権限を与えたが、開発者が便利のためにYAMLのENVを直接変更してアプリケーションを更新し、後で設定を忘れた；例えば、kubernetes YAMLをバックアップしなかったなど。

アプリケーション配信プロセス全体を組み合わせて、後で比較的簡単なソリューションを作成しました：

1. コードサーバーディスクの定期的なバックアップ
2. [kube-backup](https://github.com/zeusro/kube-backup)を使用してkubernetes YAMLをgitリポジトリに同期
3. イメージプルアカウントには`pull image`権限のみ
4. 本番レベルのリソースをデフォルトの名前空間に配置（このデフォルトの`namespace`は削除できないため）
5. 開発者の変更権限を無効にし、すべての設定を設定センター経由で行い、ほとんどのconfigmapを削除
6. 自分のadminアカウントを無効にし、削除権限のない`api-server`証明書を割り当て

ポイント5は議論の余地があります。個人的には、特定のテクノロジーに依存する場合、「**反依存性**」を考慮すべきだと思います。反依存性とは：このテクノロジーが時代遅れになったり、深刻な問題が発生した場合、私たちのプランBは何ですか？

`kubernetes`はホットアップデートメカニズムを提供していますが、ETCDの負担を軽減し、`kubernetes`への依存を減らすために、設定を`consul`に配置しました。

最高の医者は病気の前に治療し、最悪の医者は病気の後に治療します。私のように問題が現れるまで待ってから、解決方法を考えることがないように願います。

## ノード管理

TKEノードリソース計画は、実際にはやや複雑な「フェルミ推定」問題です。ノードを適切に管理および計画することで、コスト削減と効率向上に役立ちます。

ノード設定は、実際の状況に合わせる必要があります。計算集約型アプリケーションの場合、より多くのCPUを割り当て、メモリ消費型アプリケーションの場合、個人的には4コア32Gノードを好みます。

特別なノード要件を持つサービスは、Node Affinityを使用してデプロイし、要件を満たすノードにスケジュールできます。例えば、データの読み書き効率を向上させるために、MySQLを高IOモデルにスケジュールします。

GPU型ノードは一般的に特別な目的があり、通常のノードと一緒にユーザーに提供するのは適切ではありません。したがって、一般的にはノードのtaintを使用して他のノードから分離し、特別なタイプのノードが期待に合わないコンテナを実行しないようにすることをお勧めします。

    kubectl taint node $no just-for-gpu-application=true:NoExecute

```yaml
      tolerations:
        - key: "just-for-gpu-application"
          operator: "Exists"
          effect: "NoSchedule"
        - key: "just-for-gpu-application"
          operator: "Exists"
          effect: "NoExecute"          
```

個人的には、`kubernetes`クラスターに小さな設定のノード（1コア2Gなど）を追加することはお勧めしません。これはアプリケーションスケーリングの「弾力性」を失うためです。例えば、アプリケーションは最初に0.7コア1.5Gを取得しますが、しばらく実行した後、2コア4G設定が必要であることがわかります。再スケジューリングは元のノードを放棄するしかありません。さらに、このような低設定のノードは、分散システムの設計哲学—リソースの冗長性による高可用性の実現—にあまり適合していません。

では、ノード設定は常に高いほど良いのでしょうか？

この質問には実際には標準的な答えがありません。しかし、ノードの`docker hang`や`Not Ready`、さらには過度のノード負荷によって引き起こされる全体的なノード障害に何度も遭遇しました。これはノード上のすべてのアプリケーションの雪崩と利用不可を引き起こします。

![image](/img/in-post/manage-tke/npd.png)

単一ポイントノード障害によって引き起こされる問題については、クラウド監視に適切なアラートポリシーを確立することに加えて、コミュニティバージョンに基づいてNPDを強化しました。ノードの自己回復をサポートします（「[TKE NPDPlusプラグインを使用してノードの障害自己回復能力を強化](https://cloud.tencent.com/document/product/457/49376)」を参照）。ユーザーはコンテナランタイムを再起動するか、CVMを再起動することを選択できます。

さらに、TKEは[配置グループを使用して物理レベルで災害復旧を実現](https://cloud.tencent.com/document/product/457/40212#PlacementSet)することもサポートしており、クラウドサーバーの基盤ハードウェアレベルで反親和性を使用して、Podsを異なるノードに分散させます。

## ビジネス管理

`kubernetes`の`DevOps`システムは、運用と開発の両方にとって課題です。開発は一時的な存在の`pod`アーキテクチャに適応し、アプリケーションコンテナ化がもたらす変化を受け入れる必要があります。

### 揮発性

> すべてが過ぎ去る。
> 
> 私の世界では、これが真実と見なせる唯一の文かもしれません。
> 《人間失格》

揮発性にはいくつかの意味があります。まず、開発はコンテナIPが可変であるという事実に適応する必要があります。第二に、ファイルシステムも可変です。以前、コードがCVMにデプロイされたとき、サーバーにさまざまなデバッグツールをインストールできましたが、コンテナ環境では、ジレンマに直面します：デバッグツールをイメージにパッケージ化するか、`kubectl exec`を使用してコンテナに入り、インストールするか？

ツールをコンテナにパッケージ化すると、イメージにビジネスに関連しないコンテンツが含まれ、イメージが大きくなり、デプロイが遅くなります。コンテナにデバッグツールをインストールすると、更新/再起動のたびに多くの繰り返し作業に直面します。

ここでも標準的な答えは提供しませんが、他の次元でビジネス管理をどのように行うことができるかを説明します。

### 可観測性

![image](/img/in-post/manage-tke/ob.png)

現在、業界の可観測性の見解は、それを以下に分割することです：

1. Metrics
2. Tracing
3. Logging

これらの部分。この点で、Tencent CloudはPrometheusに基づいて[クラウドネイティブ監視](https://cloud.tencent.com/document/product/457/49888)ソリューション、および[ログ収集](https://cloud.tencent.com/document/product/457/48836)と[イベントストレージ](https://cloud.tencent.com/document/product/457/50988)を構築しました。これらのソリューションは、メトリクス監視、ログ収集、イベントストレージ、監視アラートなどの側面をカバーしています。

Tracingの観点から、分散サービスの追跡と監視は、非侵入的および侵入的ソリューションにさらに細分化できます。侵入的ソリューションは、コードを変更することを指し、リクエストチェーンに特定のリクエストヘッダーを追加するなどです。非侵入的ソリューションは、現在人気の`Service Mesh`アプローチで、ビジネスをビジネスにより集中させ、トラフィック制御をsidecarに任せます。スペースの制限により、ここではこれ以上展開しません。

### 分離

#### リソース分離

リソース分離は、同じクラスター内のリソース分離とマルチテナント分離にさらに細分化できます。前の章で、ノードのtaintを使用して通常のノードとGPUノードを分離することに言及しましたが、これは実際にはリソース分離の形式です。

![image](/img/in-post/manage-tke/LimitRange.png)

マルチテナンシーについては、最も簡単な実装は、ユーザーごとに1つの`namespace`、次に`LimitRange`を使用して制限することです。

リソース分離は、クラスター内だけでなく、クラスター外にも存在します。完全なリソース分離を実現するために、同じVPCまたはVPC間でクラスターを構築することがありますが、このアプローチは、クラウド間通信の新しい問題も生み出します（VPCレベルでは、[ピアリング接続](https://cloud.tencent.com/document/product/553/18836)と[クラウドネットワーキング](https://cloud.tencent.com/document/product/877/18768)を通じた通信をサポートしています）。これは、マイクロサービスアーキテクチャ全体にとって新しい課題となります。

#### ネットワーク分離

ネットワーク分離を理解するには、まず逆に**ネットワーク接続性**を理解する必要があります。`Flannel`の`VXLAN`モードを例にとると、このモードを使用する`kubernetes`クラスターノードは相互接続されています。そして実際、`namespaces`間の`services`も相互接続されています。

ここで疑問を持つ人もいるかもしれません：`kubernetes`は`namespace`に基づいてリソース分離を行っているのではないですか？なぜ`namespace`間のアクセスが相互接続されているのですか？

ここで、`kubernetes`が注入する`/etc/resolv.conf`ファイルについて言及する必要があります。`default`の下で変更されていないネットワーク設定の`pod`を例にとると：

```
cat /etc/resolv.conf
nameserver <kube-dns-vip>
search default.svc.cluster.local svc.cluster.local cluster.local localdomain
options ndots:5
```

この設定は、5レベル未満のドメインが`coreDNS`を通過し、`search`順序に従って優先順位が付けられることを意味します。例えば、baidu.comの解決は次のようになります：

```sh
sh-4.2# host -v baidu.com
Trying "baidu.com.<namespace>.svc.cluster.local"
Trying "baidu.com.svc.cluster.local"
Trying "baidu.com.cluster.local"
Trying "baidu.com.localdomain"
Trying "baidu.com"
......
```

ここで手がかりを見ることができます。例えば、`default`と`kube-system`の下に`tke-six-six-six`という名前のサービスを作成した場合、`default`の下で`six`にアクセスしても`kube-system`で定義されたサービスにジャンプしない理由は、最初に`tke-six-six-six.default.svc.cluster.local`を解決しようとするためです。しかし、`tke-six-six-six.kube-system.svc.cluster.local`に直接アクセスすることも可能です。いわゆる分離は、ドメイン解決レベルでの操作にすぎません。

ネットワーク分離は、マルチテナント環境で特に重要です。すべての入出力トラフィックが正当であることを保証できないため、まずすべてのトラフィックが不正であると仮定し、要件を満たすトラフィックのみがアプリケーションにアクセスできるようにします。`istio`を使用しない場合、公式は`ip`、`namespaceSelector`、`podSelector`に基づいて[Network Policy](https://kubernetes.io/docs/concepts/services-networking/network-policies/)も提供しています。

### 自己回復

ここで、分散システムの第一原理を再度適用します—リソースの冗長性によるシステム可用性の実現。一般的に、単一ノードの利用不可を回避するために、ユーザーにアプリケーションを2つ以上のレプリカに設定し、`podAntiAffinity`を設定することをお勧めします。

```
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: k8s-app
                      operator: In
                      values:
                        - my-pipi-server
                topologyKey: kubernetes.io/hostname
              weight: 100
```

さらに、一般的にユーザーに以下の設定を追加することをお勧めします：

1. readinessProbe（準備チェック）
2. livenessProbe（ヘルスチェック）
3. preStop hook

準備チェックとヘルスチェックの重要性は言うまでもありません。`preStop hook`は短いスリープ時間を設定できます。kube-proxyのノード転送ルールの更新アクションは即座ではないためです。PodsのコンテナにpreStop hookを追加すると、Podsは実際に破壊される前にスリープして待機し、Endpoint controllerとkube-proxyがEndpointsと転送ルールを更新する時間を提供します。

`terminationGracePeriodSeconds`のデフォルト設定は30秒であることに注意してください。`preStop hook`の時間が30秒を超える場合、`terminationGracePeriodSeconds`の値もそれに応じて変更する必要があります。

## まとめ

本から学んだことは浅い；真の知識は実践から来ます。コンテナ化は運用と開発の両方に新しいテストをもたらすため、軽視しないでください。

運用でも開発でも、運用から管理スキルを抽出し、開発で新しい~~転覆~~プログラミングの動きを解き放つことができることを願います。

![image](/img/in-post/manage-tke/win.png)

問題がないことが最大の問題です。答えがない場合は、自分で答えを見つけてください！

## 参考リンク

[1]
Introducing Container Runtime Interface (CRI) in Kubernetes
https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/

[2]
K8s宣布弃用Docker，千万别慌！
https://cloud.tencent.com/developer/article/1758588

[3]
解读：云原生下的可观察性发展方向
https://cloudnative.to/blog/cloud-native-observability/

[4]
十分钟漫谈容器网络方案 01—Flannel
https://www.infoq.cn/article/rnbqhui1wipzj6bjiwet
