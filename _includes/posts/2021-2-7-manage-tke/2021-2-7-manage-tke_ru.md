Я начал работать с `kubernetes` в середине 2018 года и возглавил преобразование традиционных приложений в сторону контейнеризации.

Объединяя реальные проблемы, с которыми столкнулись во время внедрения, и соответствующий опыт устранения неполадок, позвольте мне рассказать о том, как лучше управлять кластерами TKE.

## Управление кластером

На самом деле, перед использованием TKE вы должны задать себе вопрос. Этот вопрос называется ~~готовы ли вы столкнуться со штормом~~? О нет, это должно быть: действительно ли вы подходите для `kubernetes`?

![image](/img/in-post/manage-tke/wind.jpg)

Когда я впервые столкнулся с `kubernetes`, я был глубоко привлечён его функциями, такими как автоматическое масштабирование, самовосстановление приложений, быстрая итерация, откат версий, балансировка нагрузки и т.д. Но после использования в течение некоторого времени я был замучен до смерти мониторингом производительности приложений, сбоями узлов и диагностикой сети.

Больше всего меня впечатлило, когда разработчик JAVA задал мне такой вопрос: "Моё приложение отлично работает локально и на облачных серверах, так почему оно замедляется после контейнеризации? **Это вся ваша проблема.**"

После этого я намеренно потратил некоторое время, долго наблюдая за этим JAVA-приложением, пока не нашёл причину OOM kills и медленных ответов, и потратил субботу на исправление утечки памяти—этой **проблемы кода**—прежде чем мир наконец вернулся к прежнему спокойствию.

Да, это не проблема `kubernetes`, и это также проблема `kubernetes`. В проектировании программного обеспечения всегда была поговорка **"нет серебряной пули"**. Так называемое удобство — это просто перенос сложности в другое место. Финальная согласованность приложений зависит от различных согласований `Controller`, в то время как так называемая балансировка нагрузки — это различные правила iptable, разбросанные по всем узлам, а перезапуски приложений зависят от трудолюбивого `kubelet` на узлах.

Итак, если у вас нет смелости столкнуться с новыми вызовами, принесёнными контейнеризацией, или если масштаб вашего приложения очень мал, а частота итераций низка, я всё ещё не рекомендую вам вступать в эти мутные воды.

![image](/img/in-post/manage-tke/hammer.png)

"**Когда у вас есть молоток, всё выглядит как гвоздь.**" Это болезнь, требующая лечения. Только настоящие воины осмеливаются столкнуться с мрачной реальностью жизни.

### Планирование кластера

Предупреждён — значит вооружён. Что касается развёртывания кластера, наша [официальная документация](https://cloud.tencent.com/document/product/457/11741) на самом деле довольно подробна. Я думаю, что важные аспекты планирования кластера заключаются в выборе **среды выполнения контейнеров** и **сетевого плагина**.

Лично я думаю, что с точки зрения бизнеса `containerd` немного лучше, чем `docker`, потому что у Google и Docker Inc. разные интересы. `kubernetes` установил стандарт среды выполнения контейнеров в форме CRI с самого начала, а не напрямую используя docker. Это действие имеет значение. Предзнаменование в том, что kubernetes 1.20 откажется от поддержки docker.

Что касается сетевых плагинов, это зависит от платформы и характеристик приложения. В качестве примера возьмём Tencent Cloud, мы в настоящее время поддерживаем `GlobalRouter` и `VPC-CNI`. Проще говоря, `VPC-CNI` имеет лучшую производительность сети, но ограничен количеством ядер машины. Если приложения в основном представляют собой небольшие микросервисы (использование памяти в пределах 1G), то использование `GlobalRouter` было бы более подходящим.

Кроме того, CIDR контейнерной сети также является болевой точкой. Если диапазон CIDR установлен слишком маленьким, будет слишком мало распределяемых IP-адресов pod/service, что также повлияет на финальный масштаб приложения.

### План аварийного восстановления

Однажды передо мной была прекрасная `namespace`, которую я не ценил, пока случайно не удалил её и не понял, что всё слишком поздно. Если небеса могли бы дать мне ещё один шанс, я действительно хотел бы, чтобы мой мозг не был залит водой в то время.

![image](/img/in-post/manage-tke/tear.jpeg)

Я всё ещё помню тот инцидент. Чтобы восстановить общую доступность бизнеса, половине технического отдела пришлось работать сверхурочно до очень позднего времени. Но в процессе восстановления мы фактически обнаружили некоторые области, где предыдущая работа была недостаточной: например, предоставление разработчикам разрешения на изменение ресурсов в определённом `namespace`, но разработчики обновляли приложения для удобства, напрямую изменяя ENV в YAML, а затем забывали конфигурацию позже; например, не резервируя kubernetes YAML и т.д.

Объединяя весь процесс доставки приложений, я позже создал относительно простое решение:

1. Периодическое резервное копирование дисков сервера кода
2. Синхронизация kubernetes YAML в git-репозиторий с помощью [kube-backup](https://github.com/zeusro/kube-backup)
3. Учётные записи для извлечения образов имеют только разрешения `pull image`
4. Размещение ресурсов производственного уровня в пространстве имён по умолчанию (потому что это пространство имён по умолчанию `namespace` нельзя удалить)
5. Отключение разрешений на изменение для разработчиков, все конфигурации проходят через центр конфигурации, и удаление большинства configmaps
6. Отключение моего собственного административного аккаунта, выделение сертификата `api-server` без разрешений на удаление

Пункт 5 спорен. Лично я думаю, что когда мы зависим от определённой технологии, мы должны учитывать "**антизависимость**". Антизависимость означает: если эта технология устареет или возникнут серьёзные проблемы, каков наш план B?

Хотя `kubernetes` предоставляет механизм горячего обновления, чтобы уменьшить нагрузку на ETCD и уменьшить зависимость от `kubernetes`, мы поместили конфигурации в `consul`.

Лучший врач лечит до болезни, худший врач лечит после болезни. Я надеюсь, что все не ждут, как я, пока проблемы не появятся, прежде чем думать о том, как их решить.

## Управление узлами

Планирование ресурсов узлов TKE — это на самом деле несколько сложная проблема "оценки Ферми". Правильное управление и планирование узлов помогает лучше снизить затраты и повысить эффективность.

Конфигурация узла должна соответствовать фактическим ситуациям. Для вычислительно-интенсивных приложений выделяйте больше CPU, в то время как для приложений, потребляющих память, я лично предпочитаю узлы 4-core 32G больше.

Сервисы со специальными требованиями к узлам могут использовать Node Affinity для развёртывания, чтобы планировать на узлы, которые соответствуют требованиям. Например, планировать MySQL на модели с высоким IO для повышения эффективности чтения/записи данных.

Узлы типа GPU обычно имеют специальные цели, и неподходяще доставлять их вместе с обычными узлами пользователям. Поэтому я обычно рекомендую использовать taints узлов для изоляции их от других узлов, обеспечивая, чтобы узлы специального типа не запускали контейнеры, которые не соответствуют ожиданиям.

    kubectl taint node $no just-for-gpu-application=true:NoExecute

```yaml
      tolerations:
        - key: "just-for-gpu-application"
          operator: "Exists"
          effect: "NoSchedule"
        - key: "just-for-gpu-application"
          operator: "Exists"
          effect: "NoExecute"          
```

Я лично не рекомендую добавлять узлы с малой конфигурацией (например, 1-core 2G) в кластеры `kubernetes`, потому что это теряет "эластичность" масштабирования приложений. Например, приложение изначально получает 0.7 ядра 1.5G, но после работы в течение некоторого времени обнаруживается, что требуется конфигурация 2 ядра 4G. Переназначение может только отказаться от исходного узла. Более того, такие узлы с низкой конфигурацией не очень соответствуют философии проектирования распределённых систем—достижению высокой доступности через избыточность ресурсов.

Итак, всегда ли лучше более высокая конфигурация узла?

На этот вопрос на самом деле нет стандартного ответа. Но я много раз сталкивался с общими сбоями узлов, вызванными `docker hang` узла или `Not Ready`, или даже чрезмерной нагрузкой узла. Это вызывает лавины и недоступность всех приложений на узле.

![image](/img/in-post/manage-tke/npd.png)

Для проблем, вызванных сбоями узлов с одной точкой отказа, в дополнение к установке соответствующих политик оповещений в облачном мониторинге, мы улучшили NPD на основе версии сообщества. Он поддерживает самовосстановление узлов (см. "[Использование плагина TKE NPDPlus для повышения способности узлов к самовосстановлению при сбоях](https://cloud.tencent.com/document/product/457/49376)"). Пользователи могут выбрать перезапуск среды выполнения контейнеров или даже перезапуск CVM.

Кроме того, наш TKE также поддерживает [использование групп размещения для достижения аварийного восстановления на физическом уровне](https://cloud.tencent.com/document/product/457/40212#PlacementSet), используя антиаффинность на уровне базового оборудования облачного сервера для рассеивания Pods по разным узлам.

## Управление бизнесом

Система `DevOps` `kubernetes` является вызовом как для операций, так и для разработки. Разработка должна адаптироваться к архитектуре `pod` эфемерного существования, принимая изменения, принесённые контейнеризацией приложений.

### Волатильность

> Всё пройдёт.
> 
> В моём мире это может быть единственное предложение, которое можно считать истиной.
> 《人間失格》

Волатильность имеет несколько значений. Во-первых, разработка должна адаптироваться к тому факту, что IP-адреса контейнеров изменчивы. Во-вторых, файловая система также изменчива. Ранее, когда код развёртывался на CVM, мы могли устанавливать различные инструменты отладки на сервере, но в контейнерной среде мы сталкиваемся с дилеммой: должны ли мы упаковывать инструменты отладки в образ или использовать `kubectl exec` для входа в контейнер и установки их?

Если мы упаковываем инструменты в контейнеры, образ будет включать некоторый контент, не связанный с бизнесом, делая образ больше и развёртывание медленнее. Если мы устанавливаем инструменты отладки в контейнеры, мы сталкиваемся с большим количеством повторяющейся работы каждый раз, когда обновляем/перезапускаем.

Я также не дам стандартного ответа здесь, но расскажу вам, как управление бизнесом может быть выполнено в других измерениях.

### Наблюдаемость

![image](/img/in-post/manage-tke/ob.png)

В настоящее время взгляд отрасли на наблюдаемость заключается в том, чтобы разделить её на:

1. Metrics
2. Tracing
3. Logging

Эти части. В этом отношении мы в Tencent Cloud построили решение [облачного мониторинга](https://cloud.tencent.com/document/product/457/49888) на основе Prometheus, а также [сбор логов](https://cloud.tencent.com/document/product/457/48836) и [хранение событий](https://cloud.tencent.com/document/product/457/50988). Эти решения охватывают мониторинг метрик, сбор логов, хранение событий, мониторинг оповещений и другие аспекты.

С точки зрения Tracing, отслеживание и мониторинг распределённых сервисов могут быть дополнительно подразделены на неинвазивные и инвазивные решения. Инвазивные решения относятся к изменению кода, например, добавлению определённых заголовков запросов в цепочку запросов; неинвазивные решения — это теперь популярный подход `Service Mesh`, позволяющий бизнесу больше сосредоточиться на бизнесе, в то время как управление трафиком обрабатывается sidecar. Из-за ограничений пространства я не буду здесь расширять это.

### Изоляция

#### Изоляция ресурсов

Изоляция ресурсов может быть дополнительно подразделена на изоляцию ресурсов в пределах одного кластера и мультитенантную изоляцию. В предыдущих главах я упоминал использование taints узлов для изоляции обычных узлов и узлов GPU, что на самом деле является формой изоляции ресурсов.

![image](/img/in-post/manage-tke/LimitRange.png)

Для мультитенантности самая простая реализация — один пользователь на `namespace`, затем использование `LimitRange` для ограничения.

Изоляция ресурсов существует не только внутри кластеров, но и вне кластеров. Иногда мы строим кластеры в одном VPC или между VPC для достижения полной изоляции ресурсов, но этот подход также создаёт новые проблемы с межоблачной связью (на уровне VPC мы поддерживаем связь через [пиринговые соединения](https://cloud.tencent.com/document/product/553/18836) и [облачную сеть](https://cloud.tencent.com/document/product/877/18768)). Это будет новым вызовом для всей архитектуры микросервисов.

#### Сетевая изоляция

Чтобы понять сетевую изоляцию, мы должны сначала понять **сетевую связность** в обратном порядке. В качестве примера возьмём режим `VXLAN` `Flannel`, узлы кластера `kubernetes`, использующие этот режим, взаимосвязаны. И на самом деле, `services` между `namespaces` также взаимосвязаны.

Некоторые могут задать вопрос здесь: разве `kubernetes` не основан на `namespace` для изоляции ресурсов? Почему доступ между `namespaces` взаимосвязан?

Здесь мы должны упомянуть файл `/etc/resolv.conf`, который `kubernetes` внедряет. В качестве примера возьмём любой `pod` с неизменённой сетевой конфигурацией под `default`:

```
cat /etc/resolv.conf
nameserver <kube-dns-vip>
search default.svc.cluster.local svc.cluster.local cluster.local localdomain
options ndots:5
```

Эта конфигурация означает, что домены с менее чем пятью уровнями проходят через `coreDNS`, приоритизированные в соответствии с порядком `search`. Например, разрешение baidu.com происходит так:

```sh
sh-4.2# host -v baidu.com
Trying "baidu.com.<namespace>.svc.cluster.local"
Trying "baidu.com.svc.cluster.local"
Trying "baidu.com.cluster.local"
Trying "baidu.com.localdomain"
Trying "baidu.com"
......
```

Здесь мы можем увидеть ключ. Например, если мы создадим сервис с именем `tke-six-six-six` под `default` и `kube-system`, причина, по которой доступ к `six` под `default` не переходит к сервису, определённому в `kube-system`, заключается в том, что он сначала пытается разрешить `tke-six-six-six.default.svc.cluster.local`. Но если мы напрямую обращаемся к `tke-six-six-six.kube-system.svc.cluster.local`, это также возможно. Так называемая изоляция — это просто манипуляция на уровне разрешения домена.

Сетевая изоляция особенно важна в мультитенантных средах. Мы не можем гарантировать, что весь входящий и исходящий трафик является законным, поэтому мы сначала предполагаем, что весь трафик незаконен, позволяя только трафику, который соответствует требованиям, получать доступ к приложениям. Если не использовать `istio`, официальная версия также предоставляет [Network Policy](https://kubernetes.io/docs/concepts/services-networking/network-policies/) на основе `ip`, `namespaceSelector` и `podSelector`.

### Самовосстановление

Здесь я снова применю первый принцип распределённых систем—достижение доступности системы через избыточность ресурсов. Как правило, чтобы избежать недоступности одного узла, мы рекомендуем пользователям установить приложения на 2 или более реплик и установить `podAntiAffinity`.

```
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: k8s-app
                      operator: In
                      values:
                        - my-pipi-server
                topologyKey: kubernetes.io/hostname
              weight: 100
```

Кроме того, мы обычно рекомендуем пользователям добавить следующие конфигурации:

1. readinessProbe (проверка готовности)
2. livenessProbe (проверка здоровья)
3. preStop hook

Важность проверок готовности и проверок здоровья не требует объяснений. `preStop hook` может установить короткое время сна, потому что действие kube-proxy по обновлению правил пересылки узлов не является немедленным. Добавление preStop hook к контейнерам в Pods заставляет Pods спать и ждать в течение периода перед истинным уничтожением, давая время для Endpoint controller и kube-proxy для обновления Endpoints и правил пересылки.

Обратите внимание, что настройка по умолчанию `terminationGracePeriodSeconds` составляет 30 секунд. Если время `preStop hook` превышает 30 секунд, значение `terminationGracePeriodSeconds` также должно быть изменено соответственно.

## Резюме

То, что изучено из книг, поверхностно; истинное знание приходит из практики. Контейнеризация приносит новые испытания как для операций, так и для разработки, поэтому не относитесь к этому легкомысленно.

Я надеюсь, что все, будь то в операциях или разработке, смогут извлечь управленческие навыки из операций и разблокировать новые ~~переворот~~ программистские ходы в разработке.

![image](/img/in-post/manage-tke/win.png)

Отсутствие проблем — самая большая проблема. Если нет ответа, найдите ответ сами!

## Ссылки

[1]
Introducing Container Runtime Interface (CRI) in Kubernetes
https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/

[2]
K8s宣布弃用Docker，千万别慌！
https://cloud.tencent.com/document/product/457/11741

[3]
解读：云原生下的可观察性发展方向
https://cloudnative.to/blog/cloud-native-observability/

[4]
十分钟漫谈容器网络方案 01—Flannel
https://www.infoq.cn/article/rnbqhui1wipzj6bjiwet
